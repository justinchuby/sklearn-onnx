
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_tutorial/plot_gbegin_cst.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_tutorial_plot_gbegin_cst.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_tutorial_plot_gbegin_cst.py:


Store arrays in one onnx graph
==============================

Once a model is converted it can be useful to store an
array as a constant in the graph an retrieve it through
an output. This allows the user to store training parameters
or other informations like a vocabulary.
Last sections shows how to remove an output or to promote
an intermediate result to an output.

Train and convert a model
+++++++++++++++++++++++++

We download one model from the :epkg:`ONNX Zoo` but the model
could be trained and produced by another converter library.

.. GENERATED FROM PYTHON SOURCE LINES 20-42

.. code-block:: default

    import pprint
    import numpy
    from onnx import load
    from onnxruntime import InferenceSession
    from sklearn.datasets import load_iris
    from sklearn.linear_model import LogisticRegression
    from sklearn.model_selection import train_test_split
    from skl2onnx import to_onnx
    from skl2onnx.helpers.onnx_helper import (
        add_output_initializer,
        select_model_inputs_outputs,
    )


    data = load_iris()
    X, y = data.data.astype(numpy.float32), data.target
    X_train, X_test, y_train, y_test = train_test_split(X, y)
    model = LogisticRegression(penalty="elasticnet", C=2.0, solver="saga", l1_ratio=0.5)
    model.fit(X_train, y_train)

    onx = to_onnx(model, X_train[:1], target_opset=12, options={"zipmap": False})





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /home/xadupre/github/scikit-learn/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
      warnings.warn(




.. GENERATED FROM PYTHON SOURCE LINES 43-46

Add training parameter
++++++++++++++++++++++


.. GENERATED FROM PYTHON SOURCE LINES 46-51

.. code-block:: default


    new_onx = add_output_initializer(
        onx, ["C", "l1_ratio"], [numpy.array([model.C]), numpy.array([model.l1_ratio])]
    )








.. GENERATED FROM PYTHON SOURCE LINES 52-54

Inference
+++++++++

.. GENERATED FROM PYTHON SOURCE LINES 54-62

.. code-block:: default


    sess = InferenceSession(new_onx.SerializeToString(), providers=["CPUExecutionProvider"])
    print("output names:", [o.name for o in sess.get_outputs()])
    res = sess.run(None, {"X": X_test[:2]})
    print("outputs")
    pprint.pprint(res)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    output names: ['label', 'probabilities', 'C', 'l1_ratio']
    outputs
    [array([1, 0], dtype=int64),
     array([[2.4983161e-03, 8.6063814e-01, 1.3686356e-01],
           [9.7875208e-01, 2.1247936e-02, 2.7418587e-08]], dtype=float32),
     array([2.]),
     array([0.5])]




.. GENERATED FROM PYTHON SOURCE LINES 63-73

The major draw back of this solution is increase the prediction
time as onnxruntime copies the constants for every prediction.
It is possible either to store those constant in a separate ONNX graph
or to removes them.

Select outputs
++++++++++++++

Next function removes unneeded outputs from a model,
not only the constants. Next model only keeps the probabilities.

.. GENERATED FROM PYTHON SOURCE LINES 73-87

.. code-block:: default


    simple_onx = select_model_inputs_outputs(new_onx, ["probabilities"])

    sess = InferenceSession(
        simple_onx.SerializeToString(), providers=["CPUExecutionProvider"]
    )
    print("output names:", [o.name for o in sess.get_outputs()])
    res = sess.run(None, {"X": X_test[:2]})
    print("outputs")
    pprint.pprint(res)

    # Function *select_model_inputs_outputs* add also promote an intermediate
    # result to an output.
    #




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    output names: ['probabilities']
    outputs
    [array([[2.4983161e-03, 8.6063814e-01, 1.3686356e-01],
           [9.7875208e-01, 2.1247936e-02, 2.7418587e-08]], dtype=float32)]




.. GENERATED FROM PYTHON SOURCE LINES 88-93

This example only uses ONNX graph in memory and never saves or loads a
model. This can be done by using the following snippets of code.

Save a model
++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 93-97

.. code-block:: default


    with open("simplified_model.onnx", "wb") as f:
        f.write(simple_onx.SerializeToString())








.. GENERATED FROM PYTHON SOURCE LINES 98-100

Load a model
++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 100-109

.. code-block:: default



    model = load("simplified_model.onnx")

    sess = InferenceSession(model.SerializeToString(), providers=["CPUExecutionProvider"])
    print("output names:", [o.name for o in sess.get_outputs()])
    res = sess.run(None, {"X": X_test[:2]})
    print("outputs")
    pprint.pprint(res)




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    output names: ['probabilities']
    outputs
    [array([[2.4983161e-03, 8.6063814e-01, 1.3686356e-01],
           [9.7875208e-01, 2.1247936e-02, 2.7418587e-08]], dtype=float32)]





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 0.034 seconds)


.. _sphx_glr_download_auto_tutorial_plot_gbegin_cst.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example




    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_gbegin_cst.py <plot_gbegin_cst.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_gbegin_cst.ipynb <plot_gbegin_cst.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
